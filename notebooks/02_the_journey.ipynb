{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How We Got Here: A Research Journey\n",
    "\n",
    "This notebook documents the path from our initial hypothesis to our current findings. The failures along the way were essential they taught us what NOT to measure and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## December 2025: The Hallucination Hypothesis\n",
    "\n",
    "### The Original Idea\n",
    "\n",
    "We started with an ambitious goal: **detect hallucinations by looking at internal activation patterns.**\n",
    "\n",
    "The hypothesis was intuitive:\n",
    "- When a model generates confident, grounded text, it should have \"clean\" activation patterns\n",
    "- When it hallucinates (generates plausible-sounding nonsense), the internal structure should be different maybe more chaotic, less focused\n",
    "\n",
    "We called this \"hallucination biopsy\" diagnosing model pathology by examining its internal state.\n",
    "\n",
    "### Early Results Looked Promising\n",
    "\n",
    "Initial experiments showed large effect sizes:\n",
    "- Cohen's d > 1.0 for several metrics\n",
    "- Statistically significant differences (p < 0.001)\n",
    "- Clear visual separation in PCA plots\n",
    "\n",
    "We were excited. It seemed like we could distinguish hallucinations from grounded outputs.\n",
    "\n",
    "### Reference\n",
    "\n",
    "Early notebooks from this phase are in `archive/disproved/`. They document both the promising early results and the subsequent discovery of what went wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## January 2026: The Length Confound Discovery\n",
    "\n",
    "### The Uncomfortable Realization\n",
    "\n",
    "When we looked more carefully at our data, we noticed something troubling:\n",
    "\n",
    "**`n_active` (number of active features) correlated r = 0.96 with text length.**\n",
    "\n",
    "This was almost a perfect correlation. Longer inputs activate more features trivially, because there's more content to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Correlation Heatmap\n",
    "\n",
    "This figure shows the problem clearly:\n",
    "\n",
    "![Correlation Heatmap](../figures/paper/correlation_heatmap.png)\n",
    "\n",
    "Key observations:\n",
    "- **N Active vs Text Length: r = 0.98** Nearly perfect correlation\n",
    "- Influence and Concentration show weaker (but still concerning) correlations with length\n",
    "- Any metric correlated with length is confounded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What This Meant for Our Hallucination Results\n",
    "\n",
    "Our \"hallucination signal\" was mostly a \"longer text signal.\"\n",
    "\n",
    "In our dataset:\n",
    "- Hallucinated outputs tended to be longer (models ramble when uncertain)\n",
    "- Grounded outputs tended to be more concise\n",
    "\n",
    "We weren't detecting hallucination structure. We were detecting text length.\n",
    "\n",
    "### The Lesson\n",
    "\n",
    "> **Raw feature counts are unreliable.** They scale with input length, not semantic content. Any analysis using `n_active` without length control is suspect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## January 2026: Injection Detection Attempt\n",
    "\n",
    "### The Pivot\n",
    "\n",
    "We tried to salvage the approach by pivoting to **prompt injection detection**:\n",
    "- Adversarial prompts that try to hijack model behavior\n",
    "- Surely these would have distinct geometric signatures?\n",
    "\n",
    "### Same Problem\n",
    "\n",
    "Initial results again looked promising:\n",
    "- Clear separation between injection and benign prompts\n",
    "- Effect sizes > 1.0\n",
    "- p < 0.001\n",
    "\n",
    "But when we checked:\n",
    "- **Injection prompts were 74% longer** than benign prompts in our dataset\n",
    "- More text -> more features -> apparent \"signal\"\n",
    "\n",
    "### After Length Control\n",
    "\n",
    "When we matched prompts by length or residualized against length:\n",
    "- Effect sizes collapsed from d > 1.0 to d ~ 0.1-0.5\n",
    "- No metrics remained statistically significant\n",
    "- \"Injection\" is not a coherent geometric category\n",
    "\n",
    "### Reference\n",
    "\n",
    "The injection detection experiments are documented in `archive/disproved/`. See especially:\n",
    "- `injection_geometry_truth.ipynb` The key notebook documenting the confound discovery\n",
    "- `balanced_injection_geometry.ipynb` Balanced sampling experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## February 2026: The Real Question\n",
    "\n",
    "### Stopping to Think\n",
    "\n",
    "After two failed hypotheses, we stepped back and asked:\n",
    "\n",
    "**What CAN we actually measure with activation geometry?**\n",
    "\n",
    "We had been asking:\n",
    "- \"Can we detect bad outputs?\" (hallucinations)\n",
    "- \"Can we detect bad inputs?\" (injections)\n",
    "\n",
    "These questions assume that \"badness\" has a geometric signature. But maybe it doesn't.\n",
    "\n",
    "### The Better Question\n",
    "\n",
    "What if we asked instead:\n",
    "\n",
    "> **Can we characterize what TYPE of computation the model is doing?**\n",
    "\n",
    "Not \"is this output correct?\" but \"what cognitive mode is the model in?\"\n",
    "\n",
    "This question is more tractable because:\n",
    "- Different tasks genuinely require different processing\n",
    "- Grammar checking is structurally different from multi-hop reasoning\n",
    "- These differences should manifest in activation topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pivot That Worked\n",
    "\n",
    "### Task-Type Diagnostics\n",
    "\n",
    "We designed a clean experiment:\n",
    "1. Sample from standard NLP benchmarks (CoLA, WinoGrande, HellaSwag, MRPC, TruthfulQA)\n",
    "2. Extract attribution graphs for each sample\n",
    "3. Compute metrics from the graphs\n",
    "4. **Residualize everything against text length**\n",
    "5. Test for differences between task types\n",
    "\n",
    "### The Results\n",
    "\n",
    "After length control, we found genuine signal:\n",
    "\n",
    "| Metric | Effect Size | Interpretation |\n",
    "|: : : : |: : : : : : -|: : : : : : : : |\n",
    "| Influence (length-controlled) | d = 1.08 | **Genuine signal** |\n",
    "| Concentration (length-controlled) | d = 0.87 | **Genuine signal** |\n",
    "| N_active (length-controlled) | d = 0.07 | Collapses (was artifact) |\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "- **Grammar tasks** require focused, precise computation (is THIS word wrong?)\n",
    "- **Reasoning tasks** require diffuse, exploratory computation (how do these concepts relate?)\n",
    "- These are real cognitive differences that survive length control\n",
    "\n",
    "### The Negative Result That's Still Valuable\n",
    "\n",
    "**TruthfulQA showed no signal (d = 0.05).**\n",
    "\n",
    "True statements and false statements produce identical activation structures. This confirms:\n",
    "- We measure computation TYPE, not output QUALITY\n",
    "- Hallucination/truthfulness detection via this method is fundamentally impossible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons Learned\n",
    "\n",
    "### 1. Always Control for Confounds\n",
    "\n",
    "Especially text length in any NLP analysis. The correlation between length and feature counts is near-perfect (r = 0.96-0.98). If you don't control for it, you're measuring length.\n",
    "\n",
    "### 2. Feature Counts Are (Almost) Useless Alone\n",
    "\n",
    "`n_active` scales with input length. It tells you how long the text is, not how complex the computation is. After residualization, it carries almost no signal (d = 0.07).\n",
    "\n",
    "### 3. Influence-Based Metrics Are More Robust\n",
    "\n",
    "Mean influence and concentration capture *how* features interact, not just *how many* are active. These survive length control with strong effect sizes.\n",
    "\n",
    "### 4. Negative Results Are Valuable\n",
    "\n",
    "Learning that we CANNOT detect hallucinations is important. It:\n",
    "- Prevents others from wasting time on the same dead end\n",
    "- Clarifies the fundamental limitations of activation-based diagnostics\n",
    "- Redirects effort toward questions that DO have answers\n",
    "\n",
    "### 5. The Question Matters More Than the Method\n",
    "\n",
    "Our methodology (extract attribution graphs, compute metrics) was fine. Our QUESTION (detect hallucinations) was wrong.\n",
    "\n",
    "When we asked the right question (characterize computation types), the same methods produced robust, replicable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline Summary\n",
    "\n",
    "| Date | Phase | What Happened |\n",
    "|: : : |: : : -|: : : : : : : -|\n",
    "| Dec 2025 | Hallucination Hypothesis | Initial promising results (d > 1.0) |\n",
    "| Jan 2026 | Length Confound Discovery | Found r = 0.96 correlation with length |\n",
    "| Jan 2026 | Injection Pivot | Same problem length confounded |\n",
    "| Feb 2026 | Real Question | Asked about computation types instead |\n",
    "| Feb 2026 | Task-Type Diagnostics | Found genuine signal (d = 1.08) that survives length control |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": -\n",
    "\n",
    "*Next: [03_methodology.ipynb](03_methodology.ipynb) Technical deep-dive into how the metrics work*\n",
    "\n",
    "*Previous: [01_introduction.ipynb](01_introduction.ipynb) What this project discovers*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
