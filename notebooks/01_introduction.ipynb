{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What This Project Discovers\n",
    "\n",
    "**Language models switch between different internal processing modes depending on the task type and those modes are measurable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Question\n",
    "\n",
    "Can we measure *how* a language model thinks, not just *what* it outputs?\n",
    "\n",
    "When a model processes text, it activates thousands of internal features learned representations that encode meaning, syntax, relationships, and reasoning patterns. These features connect to each other in complex attribution graphs.\n",
    "\n",
    "We asked: **Do different types of tasks produce different internal structures?**\n",
    "\n",
    "And more specifically: Can we tell the difference between:\n",
    "- A model checking grammar\n",
    "- A model doing multi-step reasoning\n",
    "- A model detecting paraphrases\n",
    "- A model assessing truthfulness\n",
    "\n",
    "...just by looking at how information flows through its internals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Answer\n",
    "\n",
    "**Yes.** Different task types produce distinct activation topologies.\n",
    "\n",
    "More precisely:\n",
    "\n",
    "- **Grammar tasks** (like judging if a sentence is grammatically acceptable) produce *focused* computation: high influence between features, concentrated in a small number of pathways.\n",
    "\n",
    "- **Reasoning tasks** (like resolving pronoun references or selecting logical continuations) produce *diffuse* computation: lower per-feature influence, spread across many pathways.\n",
    "\n",
    "This is robust. It survives controls for text length. It replicates across different samples. The effect sizes are large (Cohen's d > 1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Finding\n",
    "\n",
    "After controlling for text length (critical see Notebook 02 for why), we found:\n",
    "\n",
    "| Metric | What It Measures | Effect Size (Cohen's d) |\n",
    "|: : : : |: : : : : : : : : |: : : : : : : : : : : : |\n",
    "| **Influence** | Causal strength between features | d = 1.08 (genuine signal) |\n",
    "| **Concentration** | Focused vs diffuse computation | d = 0.87 (genuine signal) |\n",
    "| **N_active** | Raw feature count | d = 0.07 (COLLAPSES was length artifact) |\n",
    "\n",
    "### The Pattern\n",
    "\n",
    "| Task Domain | Influence | Concentration | Interpretation |\n",
    "|: : : : : : -|: : : : : -|: : : : : : : -|: : : : : : : : |\n",
    "| Grammar (CoLA) | High | High | Focused, precise computation |\n",
    "| Reasoning (WinoGrande, HellaSwag) | Low | Low | Diffuse, exploratory computation |\n",
    "| Paraphrase (MRPC) | Medium | Medium | Moderate complexity |\n",
    "| Truthfulness (TruthfulQA) | **No signal** (d = 0.05) | **No signal** | Can't distinguish true from false |\n",
    "\n",
    "### What the Truthfulness Result Means\n",
    "\n",
    "We cannot tell if a model is lying by looking at its internal structure. True statements and false statements produce statistically identical activation patterns.\n",
    "\n",
    "This is a fundamental limitation: **we measure computation type, not output quality.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What This Means\n",
    "\n",
    "Think of it like measuring physiological signals:\n",
    "\n",
    "- **Heart rate + brain patterns** can tell you if someone is doing math versus poetry (different cognitive modes)\n",
    "- They can detect if someone is confused or uncertain (elevated activity, irregular patterns)\n",
    "- But they **cannot** tell you if the math answer is correct\n",
    "\n",
    "Similarly, our metrics tell you:\n",
    "- What *type* of computation the model is doing\n",
    "- Whether the input is anomalous or adversarial (unusual patterns)\n",
    "- How \"hard\" the model is working on a problem\n",
    "\n",
    "But they **cannot** tell you:\n",
    "- Whether the output is correct\n",
    "- Whether the model is hallucinating\n",
    "- Whether a statement is true or false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use This Repository\n",
    "\n",
    "### Directory Overview\n",
    "\n",
    "```\n",
    "notebooks/ <- YOU ARE HERE Start with these\n",
    " 01_introduction.ipynb This notebook\n",
    " 02_the_journey.ipynb How we got here (the failures that taught us)\n",
    " 03_methodology.ipynb Technical deep-dive\n",
    " 04_results.ipynb Full analysis with figures\n",
    " 05_implications.ipynb What this means for interpretability\n",
    "\n",
    "experiments/ Reproducible experiment scripts\n",
    "figures/ All generated figures\n",
    " paper/ Publication-quality versions\n",
    "data/ Input data and computed metrics\n",
    " results/ Attribution metric JSON files\n",
    "scripts/ Modal runners for GPU computation\n",
    "archive/ Historical experiments\n",
    " disproved/ Early work superseded by length control\n",
    "```\n",
    "\n",
    "### Recommended Reading Order\n",
    "\n",
    "1. **This notebook** What we found\n",
    "2. **02_the_journey** How we got here (and what didn't work)\n",
    "3. **03_methodology** How the metrics work\n",
    "4. **04_results** Full analysis with interactive figures\n",
    "5. **05_implications** Where this leads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": -\n",
    "\n",
    "*Next: [02_the_journey.ipynb](02_the_journey.ipynb) How we discovered this (and what we got wrong along the way)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
