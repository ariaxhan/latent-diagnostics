{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 2: Feature Extraction and Comparison\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Use the `hallucination_detector` package for feature extraction\n",
        "- Compare feature activations between different texts\n",
        "- Identify unique and shared features\n",
        "- Understand the foundation for hallucination detection\n",
        "\n",
        "**Estimated Time:** 15-20 minutes\n",
        "\n",
        "**Prerequisites:** Complete Tutorial 1: SAE Basics\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction: From Manual to Reusable\n",
        "\n",
        "In Tutorial 1, we manually extracted and decoded features. Now we'll use the `hallucination_detector` package, which provides clean, reusable functions for:\n",
        "\n",
        "- `initialize_model_and_sae()`: Load model and SAE\n",
        "- `extract_features()`: Get feature activations from text\n",
        "- `decode_feature()`: Translate features to words\n",
        "- `get_loudest_unique_features()`: Find features unique to one text\n",
        "- `run_differential_diagnosis()`: Compare two texts\n",
        "\n",
        "These functions form the foundation of our hallucination detection methodology.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Import from hallucination_detector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading instruments on device: mps\n",
            "  Loading SAE microscope...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loading Gemma-2-2b model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc1660a9c7294c08a78a7f5f744e46c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model gemma-2-2b into HookedTransformer\n",
            "  ✓ Instruments ready\n"
          ]
        }
      ],
      "source": [
        "from hallucination_detector import (\n",
        "    initialize_model_and_sae,\n",
        "    extract_features,\n",
        "    decode_feature,\n",
        "    get_loudest_unique_features,\n",
        "    run_differential_diagnosis,\n",
        ")\n",
        "\n",
        "# Initialize instruments\n",
        "model, sae, device = initialize_model_and_sae()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Extract Features from Multiple Texts\n",
        "\n",
        "Let's extract features from three different texts and see how they differ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features from each text:\n",
            "\n",
            "1. 'Paris is the capital of France'\n",
            "   Active features: 76\n",
            "   Total energy: 368.051\n",
            "\n",
            "2. 'The cat sat on the mat'\n",
            "   Active features: 91\n",
            "   Total energy: 406.055\n",
            "\n",
            "3. 'Machine learning uses neural networks'\n",
            "   Active features: 102\n",
            "   Total energy: 484.115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define three texts\n",
        "texts = [\n",
        "    \"Paris is the capital of France\",\n",
        "    \"The cat sat on the mat\",\n",
        "    \"Machine learning uses neural networks\"\n",
        "]\n",
        "\n",
        "# Extract features from each\n",
        "print(\"Extracting features from each text:\\n\")\n",
        "for i, text in enumerate(texts, 1):\n",
        "    features = extract_features(text, model, sae)\n",
        "    print(f\"{i}. '{text}'\")\n",
        "    print(f\"   Active features: {features['total_active']}\")\n",
        "    print(f\"   Total energy: {features['energy']:.3f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Two Texts: Finding Unique Features\n",
        "\n",
        "Now let's compare two similar texts to find features unique to each. This is the core technique for hallucination detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text A: 'The Eiffel Tower is in Paris'\n",
            "Text B: 'The Eiffel Tower is in Rome'\n",
            "\n",
            "Features unique to A: 43\n",
            "Features unique to B: 80\n",
            "Shared features: 42\n",
            "\n",
            "Top 3 loudest features unique to B:\n",
            "  1. Feature #6386 → Portale, ANSA, uolo\n",
            "  2. Feature #11133 →  Vatican, Pope,  Pope\n",
            "  3. Feature #9958 →  RB, RSD,  RCS\n"
          ]
        }
      ],
      "source": [
        "# Compare two texts\n",
        "text_a = \"The Eiffel Tower is in Paris\"\n",
        "text_b = \"The Eiffel Tower is in Rome\"\n",
        "\n",
        "print(f\"Text A: '{text_a}'\")\n",
        "print(f\"Text B: '{text_b}'\")\n",
        "print()\n",
        "\n",
        "# Extract features\n",
        "features_a = extract_features(text_a, model, sae)\n",
        "features_b = extract_features(text_b, model, sae)\n",
        "\n",
        "# Find unique features\n",
        "set_a = set(features_a['indices'])\n",
        "set_b = set(features_b['indices'])\n",
        "\n",
        "unique_to_a = set_a - set_b\n",
        "unique_to_b = set_b - set_a\n",
        "shared = set_a & set_b\n",
        "\n",
        "print(f\"Features unique to A: {len(unique_to_a)}\")\n",
        "print(f\"Features unique to B: {len(unique_to_b)}\")\n",
        "print(f\"Shared features: {len(shared)}\")\n",
        "print()\n",
        "\n",
        "# Get the loudest unique features in B\n",
        "loudest_b = get_loudest_unique_features(text_a, text_b, model, sae, top_k=3)\n",
        "print(f\"Top 3 loudest features unique to B:\")\n",
        "for i, feat_id in enumerate(loudest_b, 1):\n",
        "    decoded = decode_feature(feat_id, model, sae, top_k=3)\n",
        "    print(f\"  {i}. Feature #{feat_id} → {', '.join(decoded['words'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Differential Diagnosis: The Full Analysis\n",
        "\n",
        "The `run_differential_diagnosis()` function performs a complete comparison, returning spectral metrics and biomarkers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIFFERENTIAL DIAGNOSIS REPORT\n",
            "============================================================\n",
            "\n",
            "Control (A): 'The Eiffel Tower is in Paris'\n",
            "Sample (B):  'The Eiffel Tower is in Rome'\n",
            "\n",
            "Spectral Metrics:\n",
            "  Control entropy: 85\n",
            "  Sample entropy:  122\n",
            "  Energy diff:     126.984\n",
            "\n",
            "Biomarkers:\n",
            "  Unique to sample: 80\n",
            "  Missing from sample: 43\n",
            "\n",
            "Top 5 unique features in sample:\n",
            "  Feature #15876 →  Wittenberg, silian,  Jind\n",
            "  Feature #5 →  صوتيه,  OnInit, ITUTION\n",
            "  Feature #11789 → ably,  Folly, WebServlet\n",
            "  Feature #4110 →  Socorro,  Jod,  AOC\n",
            "  Feature #14872 →  DC,  Canberra,  Washington\n"
          ]
        }
      ],
      "source": [
        "# Run full diagnosis\n",
        "diagnosis = run_differential_diagnosis(text_a, text_b, model, sae)\n",
        "\n",
        "print(\"DIFFERENTIAL DIAGNOSIS REPORT\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nControl (A): '{text_a}'\")\n",
        "print(f\"Sample (B):  '{text_b}'\")\n",
        "print()\n",
        "\n",
        "print(\"Spectral Metrics:\")\n",
        "print(f\"  Control entropy: {diagnosis['spectral_metrics']['control_entropy']}\")\n",
        "print(f\"  Sample entropy:  {diagnosis['spectral_metrics']['sample_entropy']}\")\n",
        "print(f\"  Energy diff:     {diagnosis['spectral_metrics']['energy_diff']:.3f}\")\n",
        "print()\n",
        "\n",
        "print(\"Biomarkers:\")\n",
        "print(f\"  Unique to sample: {diagnosis['biomarkers']['unique_to_hallucination_count']}\")\n",
        "print(f\"  Missing from sample: {diagnosis['biomarkers']['missing_grounding_count']}\")\n",
        "print()\n",
        "\n",
        "print(\"Top 5 unique features in sample:\")\n",
        "for feat_id in diagnosis['biomarkers']['top_hallucination_features']:\n",
        "    decoded = decode_feature(feat_id, model, sae, top_k=3)\n",
        "    print(f\"  Feature #{feat_id} → {', '.join(decoded['words'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "In this tutorial, you learned:\n",
        "\n",
        "1. **Reusable Functions:** How to use the `hallucination_detector` package for clean, modular code\n",
        "2. **Feature Comparison:** Techniques for comparing feature sets between texts\n",
        "3. **Unique Features:** How to identify features unique to one text (the basis of hallucination detection)\n",
        "4. **Differential Diagnosis:** A complete analytical framework for comparing texts\n",
        "\n",
        "### The Foundation for Hallucination Detection\n",
        "\n",
        "The key insight: **hallucinations activate unique features that facts don't**. By identifying these \"hallucination biomarkers,\" we can detect when a model is generating false information.\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "- **experiments/hallucination_biopsy.py**: Run the full experiment with multiple test cases\n",
        "- **Medium Article Series**: Read the detailed methodology and findings\n",
        "- **Neuronpedia**: Explore individual features at https://neuronpedia.org/gemma-2b\n",
        "\n",
        "---\n",
        "\n",
        "### Try It Yourself\n",
        "\n",
        "Modify the texts above to test your own fact/hallucination pairs:\n",
        "- \"The Great Wall of China is in China\" vs \"The Great Wall of China is in Japan\"\n",
        "- \"Water boils at 100°C\" vs \"Water boils at 50°C\"\n",
        "- \"Shakespeare wrote Hamlet\" vs \"Shakespeare wrote Harry Potter\"\n",
        "\n",
        "What patterns do you notice in the unique features?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
