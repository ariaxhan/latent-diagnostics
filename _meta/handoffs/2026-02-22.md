## CONTEXT HANDOFF

**Summary**: Building paper on LLM activation topology - measuring how inputs change internal computation shape, not just outputs.

**Goal**: Write paper on representation-level diagnostics for LLM internal states, using attribution graphs + SAE features.

**Current state**:
- Infrastructure complete, awaiting Modal attribution runs on 2 prepared datasets
- Domain run in progress (400 samples), truthfulness ready (200 samples)
- Diagnostics already ran on 136 PINT samples - confirmed length confound, identified robust metrics

**Decisions made**:
- Frame as "computational phenomenology" NOT security/injection detection
- Injection is application section, NOT thesis
- Diagnostic exploration stance - no hypothesis, just observe what separates
- No warm containers (avoid cost) - use checkpoint resume instead

**Artifacts created**:
- `MISSION.md` - persistent mission context through paper completion
- `src/neural_polygraph/datasets.py` - unified loader for 10+ datasets
- `experiments/diagnostics.py` - comprehensive A-G diagnostic suite
- `experiments/domain_analysis.py` - cross-domain signature analysis
- `experiments/truthfulness_analysis.py` - factual coherence analysis
- `scripts/modal_general_attribution.py` - robust Modal runner with checkpoints
- `data/domain_analysis/domain_samples.json` - 400 samples, 8 domains
- `data/truthfulness/truthfulness_samples.json` - 200 balanced samples

**Open threads**:
- Repo rename decision: keep `neural-polygraph` or create new? (lean: rename in place)
- Modal runs pending completion

**Next steps**:
1. Complete Modal run: `modal run scripts/modal_general_attribution.py --input-file data/domain_analysis/domain_samples.json --output-file data/results/domain_attribution_metrics.json`
2. Run truthfulness attribution
3. Analyze with `python experiments/domain_analysis.py --analyze`
4. Add more input classes as patterns emerge

**Key findings so far**:
- Length confound: r=0.96 for n_active (MUST control for this)
- mean_activation: least confounded (r=-0.224), best AUC (0.830)
- Partial correlations: signal preserved after length control
- Underpowered: only 21 injection samples in PINT set

**Warnings**:
- `attribute(text, model)` NOT `attribute(model, tokens)` - text string first
- Must call `results_volume.commit()` after checkpoint writes
- No thesis language - use "observed", "appears", not "we show that"

**File paths to read**:
- `MISSION.md` - full mission context with vector native notation
- `experiments/diagnostics/runs/20260222_110302/diagnostics_report.md` - findings
- `_meta/agentdb/agent.db` - learnings and context (sqlite3)

**Continuation prompt for new session**:
> Research project: measuring LLM activation topology - how different input classes (adversarial, factual, domain-specific) induce different internal computation patterns. Infrastructure complete, Modal attribution runs in progress. Read MISSION.md for full context, then analyze results when ready. Stance: diagnostic exploration for paper, NOT hypothesis-driven.
